import streamlit as st
import time
from datetime import datetime
from modules.interview_prepper import (generate_interview_question, score_interview_answer_stream,
                                     get_interview_question_categories, get_interview_tips,
                                     conduct_interview_session_stream)
from modules.utils import (check_api_configuration, show_api_setup_guide,
                          extract_scores, save_history, format_history_for_download,
                          auto_save_session)
import os
import base64
from io import BytesIO

# éŸ³å£°æ©Ÿèƒ½ã®ä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯
AUDIO_FEATURES_AVAILABLE = False
try:
    from gtts import gTTS
    import speech_recognition as sr
    AUDIO_FEATURES_AVAILABLE = True
except ImportError:
    pass

st.set_page_config(
    page_title="é¢æ¥å¯¾ç­–",
    page_icon="ğŸ’¼",
    layout="wide",
    initial_sidebar_state="auto"
)

# ã‚«ã‚¹ã‚¿ãƒ CSS
st.markdown("""
<style>
    .main-header {
        font-weight: bold;
        color: #333;
        padding-bottom: 1rem;
        border-bottom: 2px solid #eee;
        margin-bottom: 1rem;
    }
    .stButton>button {
        font-size: 1.1rem;
        font-weight: bold;
    }
    .mode-card {
        background-color: #f8f9fa;
        border: 1px solid #e9ecef;
        border-radius: 8px;
        padding: 2rem;
        text-align: center;
        transition: all 0.3s;
        height: 100%;
        display: flex;
        flex-direction: column;
        justify-content: space-between;
    }
    .mode-card:hover {
        transform: translateY(-5px);
        box-shadow: 0 4px 12px rgba(0,0,0,0.08);
    }
    .chat-bubble {
        padding: 1rem;
        border-radius: 10px;
        margin-bottom: 1rem;
        max-width: 80%;
        width: fit-content;
    }
    .chat-bubble.user {
        background-color: #e6f3ff;
        margin-left: auto;
        text-align: right;
    }
    .chat-bubble.ai {
        background-color: #f1f1f1;
    }
    .chat-bubble-role {
        font-weight: bold;
        font-size: 0.9em;
        margin-bottom: 0.5rem;
    }
</style>
""", unsafe_allow_html=True)


# --- ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ç®¡ç† ---
def initialize_session_state():
    # ãƒšãƒ¼ã‚¸å…¨ä½“ã§å…±æœ‰
    if 'interview_mode' not in st.session_state:
        st.session_state.interview_mode = None  # None, 'single', 'session'
    
    # å˜ç™ºç·´ç¿’ç”¨
    if 'single_practice_vars' not in st.session_state:
        st.session_state.single_practice_vars = {
            'question': "", 'category': "", 'step': 'setup',
            'completed': False, 'results': None, 'user_answer': "",
            'start_time': 0, 'play_question_audio': False
        }

    # æ¨¡æ“¬ã‚»ãƒƒã‚·ãƒ§ãƒ³ç”¨
    if 'session_practice_vars' not in st.session_state:
        st.session_state.session_practice_vars = {
            'state': 'not_started',  # not_started, ongoing, completed
            'chat_history': [],  # {'role': 'ai'/'user', 'content': '...'}
            'session_start_time': 0,
            'is_responding': False # AIãŒå¿œç­”ä¸­ã‹ã©ã†ã‹ã®ãƒ•ãƒ©ã‚°
        }

initialize_session_state()

# --- å…±é€šé–¢æ•° ---

# APIè¨­å®šç¢ºèª (å…±é€š)
api_ok, api_message = check_api_configuration()
if not api_ok:
    st.error(f"**APIè¨­å®šã‚¨ãƒ©ãƒ¼:** {api_message}")
    show_api_setup_guide()
    st.stop()

def create_audio_html(text: str, autoplay: bool = False) -> str | None:
    if not AUDIO_FEATURES_AVAILABLE: return None
    try:
        fp = BytesIO()
        tts = gTTS(text=text, lang='ja')
        tts.write_to_fp(fp)
        fp.seek(0)
        audio_base64 = base64.b64encode(fp.read()).decode('utf-8')
        autoplay_attr = "autoplay" if autoplay else ""
        return f'<audio controls {autoplay_attr} style="width: 100%;"><source src="data:audio/mp3;base64,{audio_base64}" type="audio/mp3"></audio>'
    except Exception as e:
        st.warning(f"éŸ³å£°ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        return None

def safe_recognize_speech():
    if not AUDIO_FEATURES_AVAILABLE:
        st.error("éŸ³å£°èªè­˜æ©Ÿèƒ½ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
        return ""
    try:
        r = sr.Recognizer()
        with sr.Microphone() as source:
            st.info("ãƒã‚¤ã‚¯ã«å‘ã‹ã£ã¦è©±ã—ã¦ãã ã•ã„...")
            with st.spinner("éŸ³å£°èªè­˜ä¸­..."):
                audio = r.listen(source, timeout=10, phrase_time_limit=60)
            text = r.recognize_google(audio, language='ja-JP')
            st.success("éŸ³å£°ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ã—ã¾ã—ãŸã€‚")
            return text
    except Exception as e:
        st.warning(f"éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: {e}")
        return ""

# --- ãƒ¢ãƒ¼ãƒ‰é¸æŠUI ---
def render_mode_selection():
    st.markdown('<h1 class="main-header">é¢æ¥å¯¾ç­–</h1>', unsafe_allow_html=True)
    st.markdown("### ç·´ç¿’ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠã—ã¦ãã ã•ã„")

    col1, col2 = st.columns(2)
    with col1:
        with st.container(border=True, height=250):
            st.markdown("#### ğŸ¯ å˜ç™ºç·´ç¿’")
            st.write("ç‰¹å®šã®è³ªå•ã«å¯¾ã—ã¦ã€é›†ä¸­çš„ã«å›ç­”ã‚’ç·´ç¿’ã—ã¾ã™ã€‚ä¸€ã¤ä¸€ã¤ã®å›ç­”ã‚’æ·±ãæ˜ã‚Šä¸‹ã’ãŸã„å ´åˆã«ãŠã™ã™ã‚ã§ã™ã€‚")
            if st.button("å˜ç™ºç·´ç¿’ã‚’å§‹ã‚ã‚‹", use_container_width=True, type="secondary"):
                st.session_state.interview_mode = 'single'
                st.rerun()
    with col2:
        with st.container(border=True, height=250):
            st.markdown("#### ğŸ’¬ æ¨¡æ“¬é¢æ¥ã‚»ãƒƒã‚·ãƒ§ãƒ³")
            st.write("å…¥å®¤ã‹ã‚‰é€€å®¤ã¾ã§ã€å®Ÿéš›ã®é¢æ¥ã«è¿‘ã„æµã‚Œã§ç·´ç¿’ã—ã¾ã™ã€‚æ–‡è„ˆã‚’ç¶­æŒã—ãŸAIã¨ã®å¯¾è©±ã‚’é€šã˜ã¦ã€ç·åˆçš„ãªé¢æ¥åŠ›ã‚’é›ãˆã¾ã™ã€‚")
            if st.button("æ¨¡æ“¬é¢æ¥ã‚’å§‹ã‚ã‚‹", use_container_width=True, type="primary"):
                st.session_state.interview_mode = 'session'
                st.rerun()

# --- å˜ç™ºç·´ç¿’ãƒ¢ãƒ¼ãƒ‰ ---
def run_single_practice():
    st.markdown('<h1 class="main-header">é¢æ¥å¯¾ç­– (å˜ç™ºç·´ç¿’)</h1>', unsafe_allow_html=True)
    
    # çŠ¶æ…‹ã‚’ãƒ­ãƒ¼ã‚«ãƒ«å¤‰æ•°ã«å±•é–‹ï¼ˆå€‹åˆ¥ã«å‚ç…§ï¼‰
    vars_dict = st.session_state.single_practice_vars
    
    # å®Œäº†å¾Œã®è¡¨ç¤º
    if vars_dict.get('completed', False) and vars_dict.get('results'):
        st.success("è©•ä¾¡ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
        st.markdown("### è©•ä¾¡çµæœ")
        with st.container(border=True):
            st.markdown(vars_dict['results'])
        
        # è¿½åŠ è³ªå•æ©Ÿèƒ½
        from modules.utils import render_followup_chat, clear_followup_chat
        
        # å…ƒã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æº–å‚™
        original_content = {
            'question': vars_dict.get('question', ''),
            'answer': vars_dict.get('user_answer', '')
        }
        
        # è¿½åŠ è³ªå•ãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½
        render_followup_chat(
            original_content=original_content,
            original_results=vars_dict['results'],
            question_type="é¢æ¥",
            session_key="interview_followup"
        )
        
        # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒœã‚¿ãƒ³
        st.markdown("---")
        st.markdown("#### æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³")
        col1, col2 = st.columns(2)
        with col1:
            if st.button("æ–°ã—ã„è³ªå•ã§ç·´ç¿’", type="primary", use_container_width=True):
                # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚‚ã‚¯ãƒªã‚¢
                clear_followup_chat("interview_followup")
                st.session_state.single_practice_vars = {
                    'question': "", 'category': "", 'step': 'setup', 'completed': False, 
                    'results': None, 'user_answer': "", 'start_time': 0, 'play_question_audio': False
                }
                st.rerun()
        
        with col2:
            if st.button("è³ªå•å±¥æ­´ã‚’ã‚¯ãƒªã‚¢", use_container_width=True):
                clear_followup_chat("interview_followup")
                st.rerun()
        
        return

    # ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
    if vars_dict.get('step') == 'setup':
        with st.container(border=True):
            st.markdown("### è³ªå•ã®é¸æŠ")
            question_categories = get_interview_question_categories()
            tabs = st.tabs(list(question_categories.keys()))
            for tab, (category, questions) in zip(tabs, question_categories.items()):
                with tab:
                    for i, q in enumerate(questions):
                        if st.button(q, key=f"sq_{category}_{i}", use_container_width=True):
                            st.session_state.single_practice_vars.update({
                                'question': q, 'category': category, 'step': 'answering',
                                'start_time': time.time(), 'play_question_audio': True
                            })
                            st.rerun()
            if st.button("AIã§ãƒ©ãƒ³ãƒ€ãƒ ãªè³ªå•ã‚’ç”Ÿæˆ", type="primary", use_container_width=True):
                with st.spinner("AIãŒè³ªå•ã‚’ç”Ÿæˆä¸­..."):
                    res = generate_interview_question()
                    st.session_state.single_practice_vars.update({
                        'question': res['question'], 'category': res.get('category', 'ä¸€èˆ¬'),
                        'step': 'answering', 'start_time': time.time(), 'play_question_audio': True
                    })
                    st.rerun()

    # å›ç­”
    elif vars_dict.get('step') == 'answering':
        st.markdown("#### é¢æ¥å®˜ã‹ã‚‰ã®è³ªå•")
        st.info(f"##### ã€Œ{vars_dict.get('question', '')}ã€")

        audio_placeholder = st.empty()
        if vars_dict.get('play_question_audio', False):
            audio_html = create_audio_html(vars_dict.get('question', ''), autoplay=True)
            if audio_html: 
                audio_placeholder.markdown(audio_html, unsafe_allow_html=True)
            st.session_state.single_practice_vars['play_question_audio'] = False # Ensure this block runs only once
            
            # Automatically start voice recognition after playing audio
            st.info("è³ªå•ã®å†ç”ŸãŒçµ‚ã‚ã£ãŸã‚‰ã€å›ç­”ã®éŸ³å£°èªè­˜ãŒè‡ªå‹•ã§å§‹ã¾ã‚Šã¾ã™ã€‚")
            recognized_text = safe_recognize_speech()
            if recognized_text:
                st.session_state.single_practice_vars['user_answer'] = recognized_text
                st.rerun()

        answer = st.text_area("ã‚ãªãŸã®å›ç­”ï¼ˆéŸ³å£°èªè­˜å¾Œã«ç·¨é›†ã§ãã¾ã™ï¼‰", height=250, value=vars_dict.get('user_answer', ''))
        st.session_state.single_practice_vars['user_answer'] = answer
        
        col1, col2 = st.columns([1,1])
        with col1:
            if AUDIO_FEATURES_AVAILABLE:
                if st.button("ğŸ¤ ã‚‚ã†ä¸€åº¦éŸ³å£°ã§å…¥åŠ›ã™ã‚‹", use_container_width=True):
                    recognized_text = safe_recognize_speech()
                    if recognized_text:
                        st.session_state.single_practice_vars['user_answer'] = recognized_text
                        st.rerun()
        
        with col2:
            if st.button("å›ç­”ã‚’æå‡ºã—ã¦è©•ä¾¡ã‚’å—ã‘ã‚‹", type="primary", disabled=len(answer) < 10, use_container_width=True):
                st.session_state.single_practice_vars['step'] = 'scoring'
                st.rerun()

    # è©•ä¾¡
    elif vars_dict.get('step') == 'scoring':
        st.info("AIãŒè©•ä¾¡ä¸­ã§ã™...")
        stream = score_interview_answer_stream(vars_dict.get('question', ''), vars_dict.get('user_answer', ''))
        with st.container(border=True):
            feedback = st.write_stream(stream)
        st.session_state.single_practice_vars['results'] = feedback
        st.session_state.single_practice_vars['completed'] = True
        # å±¥æ­´ä¿å­˜
        history_data = {
            "type": "é¢æ¥å¯¾ç­–(å˜ç™º)", "date": datetime.now().isoformat(),
            "inputs": {"question": vars_dict.get('question', ''), "answer": vars_dict.get('user_answer', '')},
            "feedback": feedback, "scores": extract_scores(feedback)
        }
        save_history(history_data)
        st.rerun()

# --- æ¨¡æ“¬é¢æ¥ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ¢ãƒ¼ãƒ‰ ---
def run_session_practice():
    st.markdown('<h1 class="main-header">é¢æ¥å¯¾ç­– (æ¨¡æ“¬é¢æ¥ã‚»ãƒƒã‚·ãƒ§ãƒ³)</h1>', unsafe_allow_html=True)
    
    # çŠ¶æ…‹ã‚’ãƒ­ãƒ¼ã‚«ãƒ«å¤‰æ•°ã«å±•é–‹
    state = st.session_state.session_practice_vars

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´è¡¨ç¤º
    for msg in state['chat_history']:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])
            # AIã®å¿œç­”ã«éŸ³å£°å†ç”Ÿãƒœã‚¿ãƒ³ã‚’è¿½åŠ 
            if msg["role"] == "ai" and AUDIO_FEATURES_AVAILABLE:
                audio_html = create_audio_html(msg["content"])
                if audio_html:
                    st.markdown(audio_html, unsafe_allow_html=True)


    # ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯
    if state['state'] == 'not_started':
        if st.button("æ¨¡æ“¬é¢æ¥ã‚’é–‹å§‹ã™ã‚‹", type="primary", use_container_width=True):
            state['state'] = 'ongoing'
            state['is_responding'] = True
            st.rerun()

    elif state['state'] == 'ongoing':
        # AIã®å¿œç­”ã‚’å‡¦ç† (ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹ç›´å¾Œã¾ãŸã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›å¾Œ)
        if state['is_responding']:
            with st.chat_message("ai"):
                placeholder = st.empty()
                full_response = ""
                # å±¥æ­´ãŒç©ºã®å ´åˆã€æœ€åˆã®ç™ºè¨€ã‚’ç”Ÿæˆ
                stream = conduct_interview_session_stream(state['chat_history'])
                for chunk in stream:
                    if hasattr(chunk, 'text') and chunk.text:
                        full_response += chunk.text
                        placeholder.markdown(full_response + "â–Œ")
                placeholder.markdown(full_response)
                
            state['chat_history'].append({"role": "ai", "content": full_response})
            state['is_responding'] = False
            
            # çµ‚äº†åˆ¤å®š
            if "---" in full_response and "ã€ç·åˆãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã€‘" in full_response:
                state['state'] = 'completed'
                feedback_part = full_response.split("---", 1)[1]
                history_data = {
                    "type": "é¢æ¥å¯¾ç­–(ã‚»ãƒƒã‚·ãƒ§ãƒ³)", "date": datetime.now().isoformat(),
                    "inputs": {"conversation": state['chat_history']},
                    "feedback": feedback_part, "scores": extract_scores(feedback_part)
                }
                save_history(history_data)
            
            st.rerun()

        # --- ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚¨ãƒªã‚¢ ---
        # AIãŒå¿œç­”ä¸­ã§ãªã„å ´åˆã«ã®ã¿è¡¨ç¤º
        if not state['is_responding']:
            # éŸ³å£°å…¥åŠ›ãƒœã‚¿ãƒ³
            if AUDIO_FEATURES_AVAILABLE:
                if st.button("ğŸ¤ éŸ³å£°ã§å›ç­”ã™ã‚‹", use_container_width=True):
                    recognized_text = safe_recognize_speech()
                    if recognized_text:
                        state['chat_history'].append({"role": "user", "content": recognized_text})
                        state['is_responding'] = True
                        st.rerun()

            # ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›
            prompt = st.chat_input("ã¾ãŸã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã§å›ç­”ã‚’å…¥åŠ›", disabled=state['is_responding'])
            if prompt:
                state['chat_history'].append({"role": "user", "content": prompt})
                state['is_responding'] = True
                st.rerun()

    elif state['state'] == 'completed':
        st.success("æ¨¡æ“¬é¢æ¥ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒå®Œäº†ã—ã¾ã—ãŸã€‚ãŠç–²ã‚Œæ§˜ã§ã—ãŸï¼")
        st.info("æœ€çµ‚è©•ä¾¡ã¯ä¸Šè¨˜ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®æœ«å°¾ã«è¨˜è¼‰ã•ã‚Œã¦ã„ã¾ã™ã€‚")
        if st.button("æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’å§‹ã‚ã‚‹", type="primary"):
            st.session_state.session_practice_vars = {
                'state': 'not_started', 'chat_history': [], 
                'session_start_time': 0, 'is_responding': False
            }
            st.rerun()


# --- ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒãƒ³ ---
def main():
    if st.session_state.interview_mode is None:
        render_mode_selection()
    elif st.session_state.interview_mode == 'single':
        run_single_practice()
    elif st.session_state.interview_mode == 'session':
        run_session_practice()

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.header("é¢æ¥å¯¾ç­–")
        if st.session_state.interview_mode:
            if st.button("ãƒ¢ãƒ¼ãƒ‰é¸æŠã«æˆ»ã‚‹", use_container_width=True):
                st.session_state.interview_mode = None
                # reset states
                initialize_session_state()
                st.rerun()
        
        st.markdown("---")
        st.markdown("##### éŸ³å£°æ©Ÿèƒ½")
        if AUDIO_FEATURES_AVAILABLE:
            st.success("åˆ©ç”¨å¯èƒ½")
        else:
            st.warning("åˆ©ç”¨ä¸å¯ã€‚`uv pip install gtts SpeechRecognition` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

if __name__ == "__main__":
    main()

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®è‡ªå‹•ä¿å­˜
    auto_save_session(page_key="interview")
