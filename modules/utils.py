import streamlit as st
import json
import os
import re
from datetime import datetime
from google import genai
import pickle
import hashlib

HISTORY_DIR = "history"
SESSION_BACKUP_DIR = "session_backup"

# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
for dir_path in [HISTORY_DIR, SESSION_BACKUP_DIR]:
    if not os.path.exists(dir_path):
        os.makedirs(dir_path)

def get_session_id():
    """
    ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ç”¨ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯IDã‚’ç”Ÿæˆã—ã¾ã™ã€‚
    
    Returns:
        str: ã‚»ãƒƒã‚·ãƒ§ãƒ³ID
    """
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‹ã‚‰IDã‚’å–å¾—ã€ãªã‘ã‚Œã°ç”Ÿæˆ
    if 'session_id' not in st.session_state:
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®IPã‚¢ãƒ‰ãƒ¬ã‚¹ã‚„ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‹ã‚‰ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã‚’ç”Ÿæˆ
        import time
        session_data = f"{time.time()}_{id(st.session_state)}"
        st.session_state.session_id = hashlib.md5(session_data.encode()).hexdigest()[:12]
    
    return st.session_state.session_id

def save_session_backup(session_data):
    """
    ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¾ã™ã€‚
    
    Args:
        session_data (dict): ä¿å­˜ã™ã‚‹ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿
    """
    try:
        session_id = get_session_id()
        backup_file = os.path.join(SESSION_BACKUP_DIR, f"session_{session_id}.json")
        
        # JSONã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºå¯èƒ½ãªå½¢å¼ã«å¤‰æ›
        serializable_data = {}
        for key, value in session_data.items():
            try:
                json.dumps(value)  # JSONåŒ–ãƒ†ã‚¹ãƒˆ
                serializable_data[key] = value
            except (TypeError, ValueError):
                # ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºã§ããªã„å€¤ã¯æ–‡å­—åˆ—åŒ–
                serializable_data[key] = str(value)
        
        with open(backup_file, 'w', encoding='utf-8') as f:
            json.dump(serializable_data, f, ensure_ascii=False, indent=2)
            
    except Exception as e:
        st.warning(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

def load_session_backup():
    """
    ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å¾©å…ƒã—ã¾ã™ã€‚
    
    Returns:
        dict or None: å¾©å…ƒã•ã‚ŒãŸã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿
    """
    try:
        session_id = get_session_id()
        backup_file = os.path.join(SESSION_BACKUP_DIR, f"session_{session_id}.json")
        
        if os.path.exists(backup_file):
            with open(backup_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return None
        
    except Exception as e:
        st.warning(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return None

def cleanup_old_session_backups(max_age_hours=24):
    """
    å¤ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã™ã€‚
    
    Args:
        max_age_hours (int): å‰Šé™¤å¯¾è±¡ã®çµŒéæ™‚é–“ï¼ˆæ™‚é–“ï¼‰
    """
    try:
        import time
        current_time = time.time()
        max_age_seconds = max_age_hours * 3600
        
        for filename in os.listdir(SESSION_BACKUP_DIR):
            if filename.startswith('session_') and filename.endswith('.json'):
                file_path = os.path.join(SESSION_BACKUP_DIR, filename)
                file_age = current_time - os.path.getmtime(file_path)
                
                if file_age > max_age_seconds:
                    os.remove(file_path)
                    
    except Exception as e:
        # ã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–ï¼ˆã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å¤±æ•—ã¯è‡´å‘½çš„ã§ã¯ãªã„ï¼‰
        pass

def restore_exam_session():
    """
    è©¦é¨“ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’å¾©å…ƒã—ã¾ã™ï¼ˆãƒªãƒ­ãƒ¼ãƒ‰è€æ€§ï¼‰ã€‚
    
    Returns:
        bool: å¾©å…ƒã«æˆåŠŸã—ãŸã‹ã©ã†ã‹
    """
    try:
        backup_data = load_session_backup()
        if not backup_data:
            return False
        
        # é‡è¦ãªã‚»ãƒƒã‚·ãƒ§ãƒ³å¤‰æ•°ã®ã¿å¾©å…ƒ
        restore_keys = [
            'start_time', 'paper_data', 'essay_theme', 'exam_step',
            'search_keywords', 'time_extended', 'exam_completed',
            'exam_results', 'submitted_data'
        ]
        
        restored_count = 0
        for key in restore_keys:
            if key in backup_data and key not in st.session_state:
                st.session_state[key] = backup_data[key]
                restored_count += 1
        
        return restored_count > 0
        
    except Exception as e:
        st.warning(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³å¾©å…ƒä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return False

def auto_save_session():
    """
    ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’è‡ªå‹•ä¿å­˜ã—ã¾ã™ã€‚
    """
    try:
        # ä¿å­˜å¯¾è±¡ã®ã‚­ãƒ¼ã‚’æŒ‡å®š
        save_keys = [
            'start_time', 'paper_data', 'essay_theme', 'exam_step',
            'search_keywords', 'time_extended', 'exam_completed',
            'exam_results', 'submitted_data', 'session_id',
            'knowledge_checker', 'interview_mode', 'single_practice_vars',
            'session_practice_vars'
        ]
        
        save_data = {}
        for key in save_keys:
            if key in st.session_state:
                # st.session_stateã¯ç›´æ¥ã¯JSONã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºã§ããªã„ã®ã§ã€è¾æ›¸ã«å¤‰æ›
                if hasattr(st.session_state[key], 'to_dict'):
                     save_data[key] = st.session_state[key].to_dict()
                else:
                     save_data[key] = st.session_state[key]

        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’è¿½åŠ 
        save_data['last_saved'] = datetime.now().isoformat()
        
        save_session_backup(save_data);
        
        # å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        cleanup_old_session_backups()
        
    except Exception as e:
        # è‡ªå‹•ä¿å­˜ã®ã‚¨ãƒ©ãƒ¼ã¯è¡¨ç¤ºã—ãªã„ï¼ˆUXã‚’æãªã†ãŸã‚ï¼‰
        pass

def check_api_configuration():
    """
    Google Gemini APIã®è¨­å®šã‚’ç¢ºèªã—ã€é©åˆ‡ã«ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ã—ã¾ã™ã€‚
    APIã®ç–é€šç¢ºèªã¯è¡Œã‚ãšã€ã‚­ãƒ¼ã®å­˜åœ¨ã¨å½¢å¼ã®ã¿ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¾ã™ã€‚
    
    Returns:
        tuple: (bool, str) - (è¨­å®šOK?, ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸)
    """
    try:
        # ç’°å¢ƒå¤‰æ•°ã¾ãŸã¯Streamlit secretsã‹ã‚‰APIã‚­ãƒ¼ã‚’ç¢ºèª
        api_key = os.environ.get("GOOGLE_API_KEY") or st.secrets.get("GOOGLE_API_KEY")
            
        if not api_key:
            return False, "Google Gemini APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ç’°å¢ƒå¤‰æ•°GOOGLE_API_KEYã¾ãŸã¯Streamlit secretsã«è¨­å®šã—ã¦ãã ã•ã„ã€‚"
        
        # APIã‚­ãƒ¼ã®åŸºæœ¬çš„ãªå½¢å¼ãƒã‚§ãƒƒã‚¯
        if not api_key.strip() or len(api_key.strip()) < 30:
            return False, "APIã‚­ï¿½ï¿½ï¿½ã®å½¢å¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚æœ‰åŠ¹ãªGoogle Gemini APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚"
        
        return True, "APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã™ã€‚"
            
    except Exception as e:
        return False, f"APIè¨­å®šç¢ºèªä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"


def show_api_setup_guide():
    """
    APIè¨­å®šã®ã‚¬ã‚¤ãƒ‰ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚
    """
    with st.expander("ğŸ”§ APIè¨­å®šã‚¬ã‚¤ãƒ‰", expanded=True):
        st.markdown("""
        ### Google Gemini APIè¨­å®šæ‰‹é †
        
        1. **APIã‚­ãƒ¼ã®å–å¾—**
           - [Google AI Studio](https://aistudio.google.com/) ã«ã‚¢ã‚¯ã‚»ã‚¹
           - ã€ŒGet API Keyã€ã‚’ã‚¯ãƒªãƒƒã‚¯
           - APIã‚­ãƒ¼ã‚’ã‚³ãƒ”ãƒ¼
        
        2. **ç’°å¢ƒå¤‰æ•°ã§ã®è¨­å®šï¼ˆæ¨å¥¨ï¼‰**
           ```bash
           # Windows (PowerShell)
           $env:GOOGLE_API_KEY="your-api-key-here"
           
           # Windows (Command Prompt)
           set GOOGLE_API_KEY=your-api-key-here
           
           # macOS/Linux
           export GOOGLE_API_KEY="your-api-key-here"
           ```
        
        3. **Streamlit Secretsã§ã®è¨­å®š**
           - ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ•ã‚©ãƒ«ãƒ€ã« `.streamlit/secrets.toml` ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
           - ä»¥ä¸‹ã®å†…å®¹ã‚’è¨˜è¿°ï¼š
           ```toml
           GOOGLE_API_KEY = "your-api-key-here"
           ```
        
        4. **ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®å†èµ·å‹•**
           - è¨­å®šå¾Œã€Streamlitã‚¢ãƒ—ãƒªã‚’å†èµ·å‹•ã—ã¦ãã ã•ã„
        """)

def safe_api_call(func, *args, **kwargs):
    """
    APIå‘¼ã³å‡ºã—ã‚’å®‰å…¨ã«å®Ÿè¡Œã—ã€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’è¡Œã„ã¾ã™ã€‚
    
    Args:
        func: å®Ÿè¡Œã™ã‚‹é–¢æ•°
        *args: é–¢æ•°ã®å¼•æ•°
        **kwargs: é–¢æ•°ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å¼•æ•°
    
    Returns:
        tuple: (bool, result) - (æˆåŠŸ?, çµæœã¾ãŸã¯ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸)
    """
    try:
        result = func(*args, **kwargs)
        return True, result
    except Exception as e:
        error_msg = f"APIå‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
        return False, error_msg

def save_history(data):
    """Saves a record to the history directory."""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = os.path.join(HISTORY_DIR, f"{timestamp}.json")
    try:
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        return filename
    except IOError as e:
        st.error(f"å±¥æ­´ã®ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None

def load_history():
    """Loads all history records."""
    if not os.path.exists(HISTORY_DIR):
        return []
    history_files = sorted([f for f in os.listdir(HISTORY_DIR) if f.endswith('.json')], reverse=True)
    history = []
    for filename in history_files:
        try:
            with open(os.path.join(HISTORY_DIR, filename), "r", encoding="utf-8") as f:
                history.append(json.load(f))
        except (json.JSONDecodeError, IOError) as e:
            st.error(f"å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ« '{filename}' ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    return history

def extract_scores(feedback):
    """Extracts scores from the feedback text by parsing a JSON block, with a regex fallback."""
    scores = {}
    # Attempt to find and parse the JSON block
    json_match = re.search(r'\*\*ã‚¹ã‚³ã‚¢:\*\*```json\s*({.*?})\s*```', feedback, re.DOTALL)
    if json_match:
        try:
            scores = json.loads(json_match.group(1))
            # Ensure all values are integers
            for key, value in scores.items():
                scores[key] = int(value)
            return scores
        except (json.JSONDecodeError, ValueError) as e:
            st.warning(f"ã‚¹ã‚³ã‚¢ã®JSONãƒ‘ãƒ¼ã‚¹ã¾ãŸã¯å€¤å¤‰æ›ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚æ—§å½¢å¼ã§æŠ½å‡ºã‚’è©¦ã¿ã¾ã™: {e}")

    # Fallback to regex if JSON parsing fails or JSON block is not found
    score_pattern = re.compile(r"\*\*([a-zA-Z0-9\u4e00-\u9fa5]+)[:ï¼š]:\*\*\s*(\d+)")
    matches = score_pattern.findall(feedback)
    for key, score in matches:
        scores[key] = int(score)
    return scores

def format_history_for_download(data):
    """Formats a history record into a string for downloading."""
    s = f"# {data['type']} ç·´ç¿’çµæœ\n\n"
    s += f"å®Ÿæ–½æ—¥æ™‚: {datetime.fromisoformat(data['date']).strftime('%Y/%m/%d %H:%M')}\n\n"
    
    if data['type'] == "æ¡ç”¨è©¦é¨“":
        s += f"## èª²é¡Œ\n\n"
        s += f"### Abstract\n{data['inputs']['abstract']}\n\n"
        if data['inputs'].get('citations'):
            s += f"### å¼•ç”¨å…ƒ\n"
            for citation in data['inputs']['citations']:
                s += f"- [{citation['title']}]({citation['uri']})\n"
            s += "\n"
        s += f"### å°è«–æ–‡ãƒ†ãƒ¼ãƒ\n{data['inputs']['essay_theme']}\n\n"
        s += f"## ã‚ãªãŸã®å›ç­”\n\n"
        s += f"### æ—¥æœ¬èªè¨³\n{data['inputs']['translation']}\n\n"
        s += f"### æ„è¦‹\n{data['inputs']['opinion']}\n\n"
        s += f"### å°è«–æ–‡\n{data['inputs']['essay']}\n\n"
    elif data['type'] == "å°è«–æ–‡å¯¾ç­–":
        s += f"## èª²é¡Œ\n\n"
        s += f"### ãƒ†ãƒ¼ãƒ\n{data['inputs']['theme']}\n\n"
        s += f"## ã‚ãªãŸã®å›ç­”\n\n"
        s += f"### æ§‹æˆãƒ¡ãƒ¢\n{data['inputs']['memo']}\n\n"
        s += f"### æ¸…æ›¸\n{data['inputs']['essay']}\n\n"
    elif data['type'] == "é¢æ¥å¯¾ç­–":
        s += f"## è³ªå•\n\n{data['inputs']['question']}\n\n"
        s += f"## ã‚ãªãŸã®å›ç­”\n\n{data['inputs']['answer']}\n\n"

    s += f"## AIã«ã‚ˆã‚‹æ¡ç‚¹çµæœ\n\n{data['feedback']}"
    return s

def handle_submission(feedback_stream, history_data_base):
    """Handles the streaming feedback, saving, and download button logic."""
    st.subheader("æ¡ç‚¹çµæœ")
    feedback_placeholder = st.empty()
    full_feedback = ""
    try:
        for chunk in feedback_stream:
            # hasattrã§chunkã«textå±æ€§ãŒã‚ã‚‹ã‹ç¢ºèª
            if hasattr(chunk, 'text'):
                full_feedback += chunk.text
                feedback_placeholder.markdown(full_feedback + "â–Œ")
            else:
                # textå±æ€§ãŒãªã„å ´åˆ(ã‚¨ãƒ©ãƒ¼ãªã©)ã®å‡¦ç†
                st.warning("ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ãƒãƒ£ãƒ³ã‚¯ã«äºˆæœŸã›ã¬å½¢å¼ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚")

        feedback_placeholder.markdown(full_feedback)

        scores = extract_scores(full_feedback)
        history_data = {**history_data_base, "feedback": full_feedback, "scores": scores}
        
        filename = save_history(history_data)
        if filename:
            st.success("çµæœã‚’å­¦ç¿’å±¥æ­´ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")
            download_content = format_history_for_download(history_data)
            st.download_button(
                label="çµæœã‚’ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=download_content,
                file_name=f"result_{os.path.splitext(os.path.basename(filename))[0]}.txt",
                mime="text/plain"
            )
    except Exception as e:
        st.error(f"çµæœã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        if full_feedback:
            st.info("éƒ¨åˆ†çš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯:")
            st.markdown(full_feedback)

def reset_session_state(keys_to_reset):
    """
    æŒ‡å®šã•ã‚ŒãŸã‚­ãƒ¼ã®ãƒªã‚¹ãƒˆã«åŸºã¥ã„ã¦ã‚»ãƒƒã‚·ãƒ§ãƒ³å¤‰æ•°ã‚’ãƒªã‚»ãƒƒãƒˆã™ã‚‹ã€‚
    """
    for key in keys_to_reset:
        if key in st.session_state:
            del st.session_state[key]